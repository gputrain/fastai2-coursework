{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bf2c1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio\n",
    "\n",
    "from fastai.vision.all import *\n",
    "from fastai.data.all import *\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from matplotlib.pyplot import specgram\n",
    "import librosa\n",
    "import librosa.display\n",
    "from huggingface_hub import hf_hub_download\n",
    "from fastai.learner import load_learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "106ee5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_file = hf_hub_download(\"gputrain/UrbanSound8K-model\", \"UrbanSound8K.csv\")\n",
    "\n",
    "model_file = hf_hub_download(\"gputrain/UrbanSound8K-model\", \"model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec761772",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(ref_file) \n",
    "df['fname'] = df[['slice_file_name','fold']].apply (lambda x: str(x['slice_file_name'][:-4])+'.png'.strip(),axis=1 )\n",
    "my_dict = dict(zip(df.fname,df['class']))\n",
    "def label_func(f_name):\n",
    "    f_name = str(f_name).split('/')[-1:][0]\n",
    "    return my_dict[f_name]\n",
    "model = load_learner (model_file)\n",
    "EXAMPLES_PATH = Path(\"./examples\")\n",
    "labels = model.dls.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffee3f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"article.md\") as f:\n",
    "    article = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1107775",
   "metadata": {},
   "outputs": [],
   "source": [
    "interface_options = {\n",
    "    \"title\": \"Urban Sound 8K Classification\",\n",
    "    \"description\": \"Fast AI example of using a pre-trained Resnet34 vision model for an audio classification task on the [Urban Sounds](https://urbansounddataset.weebly.com/urbansound8k.html) dataset. \",\n",
    "    \"article\": article,\n",
    "    \"interpretation\": \"default\",\n",
    "    \"layout\": \"horizontal\",\n",
    "    # Audio from validation file\n",
    "    \"examples\": [\"dog_bark.wav\", \"children_playing.wav\", \"air_conditioner.wav\", \"street_music.wav\", \"engine_idling.wav\",\n",
    "                \"jackhammer.wav\", \"drilling.wav\", \"siren.wav\",\"car_horn.wav\",\"gun_shot.wav\"],\n",
    "    \"allow_flagging\": \"never\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ca2cd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sounds_melspectogram (audio_file):\n",
    "\n",
    "    samples, sample_rate = librosa.load(audio_file)  #create onces with librosa\n",
    "\n",
    "    fig = plt.figure(figsize=[0.72,0.72])\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.axes.get_xaxis().set_visible(False)\n",
    "    ax.axes.get_yaxis().set_visible(False)\n",
    "    ax.set_frame_on(False)\n",
    "    melS = librosa.feature.melspectrogram(y=samples, sr=sample_rate)\n",
    "    librosa.display.specshow(librosa.power_to_db(melS, ref=np.max))\n",
    "    filename  = 'temp.png'\n",
    "    plt.savefig(filename, dpi=400, bbox_inches='tight',pad_inches=0)\n",
    "    plt.close('all')\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1d0c3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict():\n",
    "    img = PILImage.create('temp.png')\n",
    "    pred,pred_idx,probs = model.predict(img)\n",
    "    return {labels[i]: float(probs[i]) for i in range(len(labels))}\n",
    "    return labels_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "71697d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def end2endpipeline(filename):\n",
    "    convert_sounds_melspectogram(filename)\n",
    "    return predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2401c1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/gradio/deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  warnings.warn(value)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/gradio/deprecation.py:40: UserWarning: The 'type' parameter has been deprecated. Use the Number component instead.\n",
      "  warnings.warn(value)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/gradio/deprecation.py:40: UserWarning: `layout` parameter is deprecated, and it has no effect\n",
      "  warnings.warn(value)\n"
     ]
    }
   ],
   "source": [
    "demo = gradio.Interface(\n",
    "    fn=end2endpipeline,\n",
    "    inputs=gradio.inputs.Audio(source=\"upload\", type=\"filepath\"),\n",
    "    outputs=gradio.outputs.Label(num_top_classes=10),\n",
    "    **interface_options,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0252d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860/\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"900\"\n",
       "            height=\"500\"\n",
       "            src=\"http://127.0.0.1:7860/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f0370b4fac0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<gradio.routes.App at 0x7f0525622100>, 'http://127.0.0.1:7860/', None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "launch_options = {\n",
    "    \"enable_queue\": True,\n",
    "    \"share\": False,\n",
    "    #\"cache_examples\": True,\n",
    "}\n",
    "\n",
    "demo.launch(**launch_options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8554648b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p38",
   "language": "python",
   "name": "conda_pytorch_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
